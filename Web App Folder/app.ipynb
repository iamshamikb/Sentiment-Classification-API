{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCOFNrPwLy9p",
    "outputId": "cbc3d474-0c4c-4c05-9a5a-108e43dd9800"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Dec/2020 15:42:24] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [17/Dec/2020 15:42:24] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a Negetive Review.\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install pandas\n",
    "# !pip install re\n",
    "# !pip install string\n",
    "# !pip install seaborn\n",
    "# !pip install matplotlib\n",
    "# !pip install textblob\n",
    "# !pip install nltk\n",
    "# !pip install tqdm\n",
    "# !pip install spacy\n",
    "# !pip install tensorflow_hub\n",
    "# !pip install sklearn\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "path=''\n",
    "import sys\n",
    "sys.path.append(path)\n",
    "!pip install sentencepiece \n",
    "import tokenization\n",
    "\n",
    "\n",
    "contractions = {\n",
    "\"ain't\": \"am not / are not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is\",\n",
    "\"i'd\": \"I had / I would\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I shall / I will\",\n",
    "\"i'll've\": \"I shall have / I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "def decontract(raw_html):\n",
    "    for word in raw_html.split():\n",
    "        if word.lower() in contractions:\n",
    "            raw_html = raw_html.replace(word, contractions[word.lower()])\n",
    "    return raw_html\n",
    "\n",
    "\n",
    "def fun(X):\n",
    "    tf.keras.backend.clear_session()\n",
    "    max_seq_length = mymaxlen = 170\n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "    bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n",
    "\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "    \n",
    "    print('Tokeninzing...')\n",
    "    X_t = []\n",
    "    X_m = []\n",
    "    X_s = []\n",
    "    mymaxlen = 170\n",
    "    fornulls = []\n",
    "    for i in range(mymaxlen-2):\n",
    "            fornulls.append('[PAD]')\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        if len(X)==1:\n",
    "            tokens = tokenizer.tokenize(X[0])\n",
    "        else:\n",
    "            tokens = tokenizer.tokenize(X.values[i])\n",
    "        \n",
    "        if len(tokens)>=(mymaxlen-2):\n",
    "            tokens = tokens[0:(mymaxlen-2)]\n",
    "            tokens = ['[CLS]', *tokens, '[SEP]']\n",
    "            only_token = len(tokens)  \n",
    "        else:\n",
    "            tokens = ['[CLS]', *tokens, '[SEP]'] \n",
    "            only_token = len(tokens) \n",
    "            gap = max_seq_length-only_token\n",
    "            for j in range(gap):\n",
    "                tokens.append('[PAD]')\n",
    "\n",
    "        if np.asarray(tokenizer.convert_tokens_to_ids(tokens)) is not None:\n",
    "            X_t.append(np.asarray(tokenizer.convert_tokens_to_ids(tokens)))\n",
    "        else :\n",
    "            X_t.append(np.asarray(tokenizer.convert_tokens_to_ids(['[CLS]', *fornulls, '[SEP]'])))\n",
    "\n",
    "        if (np.asarray([1]*len(tokens)+[0]*(max_seq_length-len(tokens)))) is not None:\n",
    "            X_m.append(np.asarray([1]*(only_token)+[0]*(max_seq_length-only_token)))\n",
    "        else :\n",
    "            X_m.append(np.asarray([1]*len(fornulls)+[0]*(max_seq_length-len(fornulls))))\n",
    "        X_s.append(np.asarray([0]*max_seq_length))\n",
    "\n",
    "    X_t = np.asarray(X_t)\n",
    "    X_m = np.asarray(X_m)\n",
    "    X_s = np.asarray(X_s)\n",
    "    return bert_model, X_t, X_m, X_s\n",
    "\n",
    "def auc_score(y_true, y_pred):\n",
    "    return tf.py_function(roc_auc_score,(y_true,y_pred),tf.double) \n",
    "\n",
    "def simple_preprocessing_function(text):\n",
    "    text = re.sub('@\\S*\\s','',text+str(' '))      # Removing @VirginAmerica and likes of that\n",
    "    text = re.sub('http:\\S*\\s','',text+str(' '))  # Remove hyperlinks\n",
    "    text = decontract(text)                       # Decontractions\n",
    "    text = re.sub(\"[^-9A-Za-z ]\", \" \" , text)     # Remove punctuations and special charaters\n",
    "    text = re.sub(' +', ' ', text)                # Remove extra spaces\n",
    "    text = \"\".join([i.lower() for i in text if i not in string.punctuation])  # To lower case\n",
    "    return text\n",
    "\n",
    "def prediction_function(text):\n",
    "        print('Will need 10 seconds in Paperspace GPU, 2 min in Colab GPU...')\n",
    "        print('Cleaning the text...')\n",
    "        text = [simple_preprocessing_function(text)]\n",
    "        \n",
    "        print('Making BERT Ready...')\n",
    "        bert_model, Xn_test_tokens, Xn_test_mask, Xn_test_segment = fun(text)\n",
    "        print('BERT is making predictions...')\n",
    "        cl=bert_model.predict([Xn_test_tokens, Xn_test_mask, Xn_test_segment])\n",
    "        \n",
    "        print('Loading the additional Neural Network...')\n",
    "        nnmodel = tf.keras.models.load_model(\"bert_model2.hdf5\", compile=False)\n",
    "        nnmodel.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy', auc_score])\n",
    "         \n",
    "        print('Making final predictions...')                      # 0 Negetive ,1 Positive\n",
    "        predictions = nnmodel.predict(cl)[0]\n",
    "        clear_output()\n",
    "        \n",
    "        # print(round(predictions[0], 4), '% Negetive. ', round(predictions[1], 4), '% Positive.')\n",
    "        result = str(text[0]) + '::: is :::'+str(round(predictions[0], 4))+ ' % Negetive. '+ str(round(predictions[1], 4))+ ' % Positive.   Verdict- '\n",
    "\n",
    "        if nnmodel.predict(cl).argmax(axis=-1) == 0:\n",
    "            print('It is a Negetive Review.')\n",
    "            return result+'Negetive Review'\n",
    "        else:\n",
    "            print('It is a Positive Review.')\n",
    "            return result+'Positive Review'\n",
    "        print('-------------------------------------------')\n",
    "\n",
    "####################### Flask ############################\n",
    "!pip install flask-ngrok\n",
    "\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, request, render_template, jsonify\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def check_sentiment():\n",
    "    if request.method == 'POST':\n",
    "        verdict = prediction_function(request.form['input_text'])\n",
    "        # verdict = request.form['input_text']\n",
    "        return jsonify(verdict)\n",
    "    return render_template('trial.html')\n",
    "\n",
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "app.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
